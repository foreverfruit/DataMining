## 1 KDDCup99网络入侵检测数据集介绍

该数据集是从一个模拟的美国空军局域网上采集来的9个星期的网络连接数据,分成具有标识的训练数据和未加标识的测试数据。测试数据和训练数据有着不同的概率分布,测试数据包含了一些未出现在训练数据中的攻击类型,这使得入侵检测更具有现实性。
在训练数据集中包含了1种正常的标识类型normal和22种训练攻击类型,如表1-1所示。另外有14种攻击仅出现在测试数据集中。

表1-1 KDDCup99入侵检测实验数据的标识类型

| 标识类型    | 含义                 | 具体分类标识                                   |
| ------- | ------------------ | ---------------------------------------- |
| Normal  | 正常记录               | Normal                                   |
| DOS     | 拒绝服务攻击             | back、land、neptune、pod、smurf、teardrop     |
| Probing | 监视和其他探测活动          | ipsweep、nmap、portsweep、satan             |
| R2L     | 来自远程机器的非法访问        | ftp_write、guess_passwd、imap、multihop、phf、spy、warezclient、warezmaster |
| U2R     | 普通用户对本地超级用户特权的非法访问 | buffer_overflow、loadmodule、perl、rootkit  |

数据特征：KDDCup99训练数据集中每个连接记录包含了41个固定的特征属性和1个类标识,如图1-1所示,标识用来表示该条连接记录是正常的,或是某个具体的攻击类型。在41个固定的特征属性中,9个特征属性为离散(symbolic)型,其他均为连续(continuous)型。

## 2 数据预处理

聚类算法中要使用计算距离的方法对数据进行聚类，而连接记录的固定特征属性中有两种类型的数值:离散型和连续型。对于连续型特征属性,各属性的度量方法不一样。一般而言，所用的度量单位越小，变量可能的值域就越大，这样对聚类结果的影响也越大,即在计算数据间距离时对聚类的影响越大，甚至会出现“大数”吃“小数”的现象。因此为了避免对度量单位选择的依赖，消除由于属性度量的差异对聚类产生的影响，需要对属性值进行标准化。对于离散型特征属性本文中并不作标准化处理，而是放在聚类算法中计算距离时处理。所以数据标准化是针对连续型特征属性的。设训练数据集有n条网络连接记录，每个记录中有22个连续型属性向量记作Xij(1≤i≤n,11≤j≤41)。对Xij数据预处理分为两步:数值标准化和数值归一化。

表1-4以2秒时间窗口计算的流量特征

| 特征名                | 描述                      | 类型   |
| ------------------ | ----------------------- | ---- |
| count              | 过去的2秒内与当前连接有着相同的目的地址的连接 | 连续   |
| serror_rate        | 出现SYN错误的连接次数            | 连续   |
| rerror_rate        | 出现REJ错误的连接次数            | 连续   |
| same_srv_rate      | 建立相同服务的连接次数             | 连续   |
| diff_srv_rate      | 建立不同服务的连接次数             | 连续   |
| srv_count          | 过去2秒时间内出现和当前连接服务相同的连接次数 | 连续   |
| srv_serror_rate    | 出现SYN错误的连接次数            | 连续   |
| srv_rerror_rate    | 出现REJ错误的连接次数            | 连续   |
| srv_diff_host_rate | 连接不相同主机的次数              | 连续   |

### 2.1 数值标准化

设 $X'_{ij}$ 为 $X_{ij}$ 数值标准化后的值。

$X'_{ij} = \frac{ X_{ij}-AVG_j }{ STAD_j }$

$AVG_j = \frac{ 1 }{ n }(X_{1j}+X_{2j}+...+X_{nj})$

$STAD_j = \frac{ 1 }{ n }(\lvert X_{1j}-AVG_j \lvert +\lvert X_{2j}-AVG_j \lvert +...+ \lvert X_{nj}-AVG_j \lvert )$

### 2.2 数值归一化

设 $X'' _{ij}$为 $X_{ij}$归一化后的值。

$ X''_{ij} = \frac{ X'_{ij}-X _{min} } { X_{max} - X_{min} } $

$X_{min} = min{ X'_{ij} }$

$X_{max} = max{ X'_{ij} }$

其中下标变量1<=i<=n, 11<=j<=41

数值归一化处理过程及归一化后数据实例如图2-1

| 0.0             | 2.6104176374e-07 | 0.00105713002195 |
| --------------- | ---------------- | ---------------- |
| 0.0             | 0.0              | 0.0              |
| 0.0             | 0.0              | 0.0              |
| 0.0             | 0.0              | 0.0              |
| 0.0156555772994 | 0.0              | 0.0              |
| 0.0             | 0.0              | 1.0              |
| 0.0             | 0.0352941176471  | 0.0352941176471  |
| 1.0             | 0.0              | 0.11             |
| 0.0             | 0.0              | 0.0              |
| 0.0             | 1                |                  |

## 3. 样本分析

KDD99数据集总共由500万条记录构成，它还提供一个10%的训练子集和测试子集。样本类别分布表如下：

| 标签   | 类别              | 训练集(10%) | 测试集(Corrected) |
| ---- | --------------- | -------- | -------------- |
| 1    | NORMAL          | 97278    | 60593          |
| 2    | PROBE           | 4107     | 4166           |
| 3    | ipsweep         | 1247     | 306            |
| 4    | mscan           | /        | 1053           |
| 5    | nmap            | 231      | 84             |
| 6    | portsweep       | 1040     | 354            |
| 7    | saint           | /        | 736            |
| 8    | satan           | 1589     | 1633           |
| 9    | DOS             | 391458   | 229853         |
| 10   | apache2         | /        | 794            |
| 11   | back            | 2203     | 1098           |
| 12   | land            | 21       | 9              |
| 13   | mailbomb        | /        | 5000           |
| 14   | neptune         | 107201   | 58001          |
| 15   | pod             | 264      | 87             |
| 16   | processtable    | /        | 759            |
| 17   | smurf           | 280790   | 164091         |
| 18   | teardrop        | 979      | 12             |
| 19   | udpstorm        | /        | 2              |
| 20   | U2R             | 52       | 228            |
| 21   | buffer_overflow | 30       | 22             |
| 22   | httptunnel      | /        | 158            |
| 23   | loadmodule      | 9        | 2              |
| 24   | perl            | 3        | 2              |
| 25   | ps              | /        | 16             |
| 26   | rootkit         | 10       | 13             |
| 27   | sqlattack       | /        | 2              |
| 28   | xterm           | /        | 13             |
| 29   | R2L             | 1126     | 16189          |
| 30   | ftp_write       | 8        | 3              |
| 31   | guess_passwd    | 53       | 4367           |
| 32   | imap            | 12       | 1              |
| 33   | multihop        | 7        | 18             |
| 34   | named           | /        | 17             |
| 35   | phf             | 4        | 2              |
| 36   | sendmail        | /        | 17             |
| 37   | snmpgetattack   | /        | 7741           |
| 38   | snmpguess       | /        | 2406           |
| 39   | spy             | 2        | /              |
| 40   | warezclient     | 1020     | /              |
| 41   | warezmaster     | 20       | 1602           |
| 42   | worm            | /        | 2              |
| 43   | xlock           | /        | 9              |
| 44   | xsnoop          | /        | 4              |

- 训练集和测试集分别为KDD99数据集中的10%训练样本和corrected 的测试样本；
- “/”表示该种攻击类型只在测试集（或训练集）中出现，而未在训练集（或测试集）中出现；

如上表，同DARPA98一样，KDD99将攻击类型分为4类，然后又细分为39小类，每一类代表一种攻击类型，类型名被标记在训练数据集每一行记录的最后一项。
从表中可以看出，训练集中共出现了22个攻击类型，而剩下的17种只在测试集中出现，这样设计的目的是检验分类器模型的泛化能力，对未知攻击类型的检测能力是评价入侵检测。

## 4 KNN算法

### 4.1 算法介绍

kNN算法的指导思想是“近朱者赤，近墨者黑”，由你的邻居来推断出你的类别。计算步骤如下:

1. 算距离：给定测试对象，计算它与训练集中的每个对象的距离
2. 找邻居：圈定距离最近的k个训练对象，作为测试对象的近邻
3. 做分类：根据这k个近邻归属的主要类别，来对测试对象分类

### 4.2 距离或相似度的衡量

什么是合适的距离衡量？距离越近应该意味着这两个点属于一个分类的可能性越大。距离衡量包括欧式距离、夹角余弦等。本实验使用欧式(Euclidean)距离。

### 4.3 类别的判定

投票决定：少数服从多数，近邻中哪个类别的点最多就分为该类。
加权投票法：根据距离的远近，对近邻的投票进行加权，距离越近则权重越大（权重为距离平方的倒数）

### 4.4 K值的设定

k太小，分类结果易受噪声点影响；k太大，近邻中又可能包含太多的其它类别的点。（对距离加权，可以降低k值设定的影响）
k值通常是采用交叉检验来确定（以k=1为基准）
经验规则：k一般低于训练样本数的平方根

### 4.5 判定方式的选择

投票法没有考虑近邻的距离的远近，距离更近的近邻也许更应该决定最终的分类，所以加权投票法更恰当一些。

### 4.6 衡量距离的选择

高维度对距离衡量的影响：众所周知当变量数越多，欧式距离的区分能力就越差。
变量值域对距离的影响：值域越大的变量常常会在距离计算中占据主导作用，因此应先对变进行标准化。

### 4.7 数据处理